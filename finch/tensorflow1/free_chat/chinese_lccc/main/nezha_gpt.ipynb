{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nezha_gpt.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOAahQ4edahU0hGAx37e2aU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"_nc77McmHHhL","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","import os\n","os.chdir('/content/gdrive/My Drive/finch/tensorflow1/free_chat/chinese_lccc/main')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xr3XYKMgX6HL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":347},"executionInfo":{"status":"ok","timestamp":1599554279212,"user_tz":-480,"elapsed":6296,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"outputId":"4ca099ff-042f-41c7-ae05-4b12185c83bc"},"source":["%tensorflow_version 1.x\n","!pip install bert4keras"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","Collecting bert4keras\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/71/9610242a003336a67b8a13162e937e0c0da9ba6daf5821e17cc96e6aa4b2/bert4keras-0.8.7.tar.gz (40kB)\n","\u001b[K     |████████████████████████████████| 40kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: keras<=2.3.1 in /tensorflow-1.15.2/python3.6 (from bert4keras) (2.3.1)\n","Requirement already satisfied: keras-applications>=1.0.6 in /tensorflow-1.15.2/python3.6 (from keras<=2.3.1->bert4keras) (1.0.8)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras) (3.13)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras) (1.18.5)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras) (2.10.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras) (1.15.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras) (1.4.1)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras) (1.1.2)\n","Building wheels for collected packages: bert4keras\n","  Building wheel for bert4keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bert4keras: filename=bert4keras-0.8.7-cp36-none-any.whl size=39155 sha256=c279e58fd439683b079219e40834f2c2c645cb8949019e785e53ebc787ec4f8d\n","  Stored in directory: /root/.cache/pip/wheels/53/71/4c/3c37d5b70183ce174cbf51700bef11a3dcd11370ccf47052ff\n","Successfully built bert4keras\n","Installing collected packages: bert4keras\n","Successfully installed bert4keras-0.8.7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EcXtVoTUXyJL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599554284647,"user_tz":-480,"elapsed":11676,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"outputId":"e291f7c0-7b1b-401c-b247-575c4f944634"},"source":["import numpy as np\n","from bert4keras.models import build_transformer_model\n","from bert4keras.tokenizers import Tokenizer\n","from bert4keras.snippets import AutoRegressiveDecoder\n","from bert4keras.snippets import uniout"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"5Hg1RO1uX_-u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1599554352120,"user_tz":-480,"elapsed":79100,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"outputId":"4b885f7d-ccb8-4ad7-a3a3-7d928c09ce94"},"source":["config_path = '../model/nezha_gpt_dialog/config.json'\n","checkpoint_path = '../model/nezha_gpt_dialog/model.ckpt'\n","dict_path = '../model/nezha_gpt_dialog/vocab.txt'\n","\n","tokenizer = Tokenizer(dict_path, do_lower_case=True)\n","\n","model = build_transformer_model(\n","    config_path,\n","    checkpoint_path,\n","    model='nezha',\n","    application='lm',\n",")\n","model.summary()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","Input-Token (InputLayer)        (None, None)         0                                            \n","__________________________________________________________________________________________________\n","Input-Segment (InputLayer)      (None, None)         0                                            \n","__________________________________________________________________________________________________\n","Embedding-Token (Embedding)     multiple             10901760    Input-Token[0][0]                \n","                                                                 MLM-Norm[0][0]                   \n","__________________________________________________________________________________________________\n","Embedding-Segment (Embedding)   (None, None, 768)    1536        Input-Segment[0][0]              \n","__________________________________________________________________________________________________\n","Embedding-Token-Segment (Add)   (None, None, 768)    0           Embedding-Token[0][0]            \n","                                                                 Embedding-Segment[0][0]          \n","__________________________________________________________________________________________________\n","Embedding-Norm (LayerNormalizat (None, None, 768)    1536        Embedding-Token-Segment[0][0]    \n","__________________________________________________________________________________________________\n","Embedding-Dropout (Dropout)     (None, None, 768)    0           Embedding-Norm[0][0]             \n","__________________________________________________________________________________________________\n","Attention-LM-Mask (Lambda)      (1, 1, None, None)   0           Input-Token[0][0]                \n","__________________________________________________________________________________________________\n","Embedding-Relative-Position (Re (None, None, 64)     8256        Embedding-Dropout[0][0]          \n","                                                                 Embedding-Dropout[0][0]          \n","__________________________________________________________________________________________________\n","Transformer-0-MultiHeadSelfAtte (None, None, 768)    2362368     Embedding-Dropout[0][0]          \n","                                                                 Embedding-Dropout[0][0]          \n","                                                                 Embedding-Dropout[0][0]          \n","                                                                 Attention-LM-Mask[0][0]          \n","                                                                 Embedding-Relative-Position[0][0]\n","__________________________________________________________________________________________________\n","Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Embedding-Dropout[0][0]          \n","                                                                 Transformer-0-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-0-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-0-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-0-FeedForward (Feed (None, None, 768)    4722432     Transformer-0-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-0-FeedForward-Dropo (None, None, 768)    0           Transformer-0-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-0-FeedForward-Add ( (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent\n","                                                                 Transformer-0-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-0-FeedForward-Norm  (None, None, 768)    1536        Transformer-0-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-1-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-0-FeedForward-Norm[0]\n","                                                                 Transformer-0-FeedForward-Norm[0]\n","                                                                 Transformer-0-FeedForward-Norm[0]\n","                                                                 Attention-LM-Mask[0][0]          \n","                                                                 Embedding-Relative-Position[0][0]\n","__________________________________________________________________________________________________\n","Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-FeedForward-Norm[0]\n","                                                                 Transformer-1-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-1-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-1-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-1-FeedForward (Feed (None, None, 768)    4722432     Transformer-1-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-1-FeedForward-Dropo (None, None, 768)    0           Transformer-1-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-1-FeedForward-Add ( (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent\n","                                                                 Transformer-1-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-1-FeedForward-Norm  (None, None, 768)    1536        Transformer-1-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-2-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-1-FeedForward-Norm[0]\n","                                                                 Transformer-1-FeedForward-Norm[0]\n","                                                                 Transformer-1-FeedForward-Norm[0]\n","                                                                 Attention-LM-Mask[0][0]          \n","                                                                 Embedding-Relative-Position[0][0]\n","__________________________________________________________________________________________________\n","Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-FeedForward-Norm[0]\n","                                                                 Transformer-2-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-2-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-2-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-2-FeedForward (Feed (None, None, 768)    4722432     Transformer-2-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-2-FeedForward-Dropo (None, None, 768)    0           Transformer-2-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-2-FeedForward-Add ( (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent\n","                                                                 Transformer-2-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-2-FeedForward-Norm  (None, None, 768)    1536        Transformer-2-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-3-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-2-FeedForward-Norm[0]\n","                                                                 Transformer-2-FeedForward-Norm[0]\n","                                                                 Transformer-2-FeedForward-Norm[0]\n","                                                                 Attention-LM-Mask[0][0]          \n","                                                                 Embedding-Relative-Position[0][0]\n","__________________________________________________________________________________________________\n","Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-FeedForward-Norm[0]\n","                                                                 Transformer-3-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-3-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-3-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-3-FeedForward (Feed (None, None, 768)    4722432     Transformer-3-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-3-FeedForward-Dropo (None, None, 768)    0           Transformer-3-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-3-FeedForward-Add ( (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent\n","                                                                 Transformer-3-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-3-FeedForward-Norm  (None, None, 768)    1536        Transformer-3-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-4-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-3-FeedForward-Norm[0]\n","                                                                 Transformer-3-FeedForward-Norm[0]\n","                                                                 Transformer-3-FeedForward-Norm[0]\n","                                                                 Attention-LM-Mask[0][0]          \n","                                                                 Embedding-Relative-Position[0][0]\n","__________________________________________________________________________________________________\n","Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-FeedForward-Norm[0]\n","                                                                 Transformer-4-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-4-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-4-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-4-FeedForward (Feed (None, None, 768)    4722432     Transformer-4-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-4-FeedForward-Dropo (None, None, 768)    0           Transformer-4-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-4-FeedForward-Add ( (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent\n","                                                                 Transformer-4-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-4-FeedForward-Norm  (None, None, 768)    1536        Transformer-4-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-5-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-4-FeedForward-Norm[0]\n","                                                                 Transformer-4-FeedForward-Norm[0]\n","                                                                 Transformer-4-FeedForward-Norm[0]\n","                                                                 Attention-LM-Mask[0][0]          \n","                                                                 Embedding-Relative-Position[0][0]\n","__________________________________________________________________________________________________\n","Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-FeedForward-Norm[0]\n","                                                                 Transformer-5-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-5-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-5-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-5-FeedForward (Feed (None, None, 768)    4722432     Transformer-5-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-5-FeedForward-Dropo (None, None, 768)    0           Transformer-5-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-5-FeedForward-Add ( (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent\n","                                                                 Transformer-5-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-5-FeedForward-Norm  (None, None, 768)    1536        Transformer-5-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-6-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-5-FeedForward-Norm[0]\n","                                                                 Transformer-5-FeedForward-Norm[0]\n","                                                                 Transformer-5-FeedForward-Norm[0]\n","                                                                 Attention-LM-Mask[0][0]          \n","                                                                 Embedding-Relative-Position[0][0]\n","__________________________________________________________________________________________________\n","Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-FeedForward-Norm[0]\n","                                                                 Transformer-6-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-6-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-6-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-6-FeedForward (Feed (None, None, 768)    4722432     Transformer-6-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-6-FeedForward-Dropo (None, None, 768)    0           Transformer-6-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-6-FeedForward-Add ( (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent\n","                                                                 Transformer-6-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-6-FeedForward-Norm  (None, None, 768)    1536        Transformer-6-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-7-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-6-FeedForward-Norm[0]\n","                                                                 Transformer-6-FeedForward-Norm[0]\n","                                                                 Transformer-6-FeedForward-Norm[0]\n","                                                                 Attention-LM-Mask[0][0]          \n","                                                                 Embedding-Relative-Position[0][0]\n","__________________________________________________________________________________________________\n","Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-FeedForward-Norm[0]\n","                                                                 Transformer-7-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-7-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-7-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-7-FeedForward (Feed (None, None, 768)    4722432     Transformer-7-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-7-FeedForward-Dropo (None, None, 768)    0           Transformer-7-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-7-FeedForward-Add ( (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent\n","                                                                 Transformer-7-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-7-FeedForward-Norm  (None, None, 768)    1536        Transformer-7-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-8-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-7-FeedForward-Norm[0]\n","                                                                 Transformer-7-FeedForward-Norm[0]\n","                                                                 Transformer-7-FeedForward-Norm[0]\n","                                                                 Attention-LM-Mask[0][0]          \n","                                                                 Embedding-Relative-Position[0][0]\n","__________________________________________________________________________________________________\n","Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-FeedForward-Norm[0]\n","                                                                 Transformer-8-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-8-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-8-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-8-FeedForward (Feed (None, None, 768)    4722432     Transformer-8-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-8-FeedForward-Dropo (None, None, 768)    0           Transformer-8-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-8-FeedForward-Add ( (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent\n","                                                                 Transformer-8-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-8-FeedForward-Norm  (None, None, 768)    1536        Transformer-8-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-9-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-8-FeedForward-Norm[0]\n","                                                                 Transformer-8-FeedForward-Norm[0]\n","                                                                 Transformer-8-FeedForward-Norm[0]\n","                                                                 Attention-LM-Mask[0][0]          \n","                                                                 Embedding-Relative-Position[0][0]\n","__________________________________________________________________________________________________\n","Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-FeedForward-Norm[0]\n","                                                                 Transformer-9-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-9-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-9-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-9-FeedForward (Feed (None, None, 768)    4722432     Transformer-9-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-9-FeedForward-Dropo (None, None, 768)    0           Transformer-9-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-9-FeedForward-Add ( (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent\n","                                                                 Transformer-9-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-9-FeedForward-Norm  (None, None, 768)    1536        Transformer-9-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-10-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-9-FeedForward-Norm[0]\n","                                                                 Transformer-9-FeedForward-Norm[0]\n","                                                                 Transformer-9-FeedForward-Norm[0]\n","                                                                 Attention-LM-Mask[0][0]          \n","                                                                 Embedding-Relative-Position[0][0]\n","__________________________________________________________________________________________________\n","Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-9-FeedForward-Norm[0]\n","                                                                 Transformer-10-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-10-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-10-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-10-FeedForward (Fee (None, None, 768)    4722432     Transformer-10-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-10-FeedForward-Drop (None, None, 768)    0           Transformer-10-FeedForward[0][0] \n","__________________________________________________________________________________________________\n","Transformer-10-FeedForward-Add  (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten\n","                                                                 Transformer-10-FeedForward-Dropou\n","__________________________________________________________________________________________________\n","Transformer-10-FeedForward-Norm (None, None, 768)    1536        Transformer-10-FeedForward-Add[0]\n","__________________________________________________________________________________________________\n","Transformer-11-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-10-FeedForward-Norm[0\n","                                                                 Transformer-10-FeedForward-Norm[0\n","                                                                 Transformer-10-FeedForward-Norm[0\n","                                                                 Attention-LM-Mask[0][0]          \n","                                                                 Embedding-Relative-Position[0][0]\n","__________________________________________________________________________________________________\n","Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-FeedForward-Norm[0\n","                                                                 Transformer-11-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-11-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-11-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-11-FeedForward (Fee (None, None, 768)    4722432     Transformer-11-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-11-FeedForward-Drop (None, None, 768)    0           Transformer-11-FeedForward[0][0] \n","__________________________________________________________________________________________________\n","Transformer-11-FeedForward-Add  (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten\n","                                                                 Transformer-11-FeedForward-Dropou\n","__________________________________________________________________________________________________\n","Transformer-11-FeedForward-Norm (None, None, 768)    1536        Transformer-11-FeedForward-Add[0]\n","__________________________________________________________________________________________________\n","MLM-Dense (Dense)               (None, None, 768)    590592      Transformer-11-FeedForward-Norm[0\n","__________________________________________________________________________________________________\n","MLM-Norm (LayerNormalization)   (None, None, 768)    1536        MLM-Dense[0][0]                  \n","__________________________________________________________________________________________________\n","MLM-Bias (BiasAdd)              (None, None, 14195)  14195       Embedding-Token[1][0]            \n","__________________________________________________________________________________________________\n","MLM-Activation (Activation)     (None, None, 14195)  0           MLM-Bias[0][0]                   \n","==================================================================================================\n","Total params: 96,573,875\n","Trainable params: 96,565,619\n","Non-trainable params: 8,256\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ooeZ8HxPZUqn","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599554352134,"user_tz":-480,"elapsed":79102,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}}},"source":["class ChatBot(AutoRegressiveDecoder):\n","    @AutoRegressiveDecoder.wraps(default_rtype='probas')\n","    def predict(self, inputs, output_ids, states):\n","        token_ids, segment_ids = inputs\n","        token_ids = np.concatenate([token_ids, output_ids], 1)\n","        curr_segment_ids = np.ones_like(output_ids) - segment_ids[0, -1]\n","        segment_ids = np.concatenate([segment_ids, curr_segment_ids], 1)\n","        return model.predict([token_ids, segment_ids])[:, -1]\n","\n","    def response(self, texts, topk=5):\n","        token_ids, segment_ids = [tokenizer._token_start_id], [0]\n","        for i, text in enumerate(texts):\n","            ids = tokenizer.encode(text)[0][1:]\n","            token_ids.extend(ids)\n","            segment_ids.extend([i % 2] * len(ids))\n","        results = self.random_sample([token_ids, segment_ids], 1, topk)\n","        return tokenizer.decode(results[0])"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"VDe09WjKZX-T","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1599554358763,"user_tz":-480,"elapsed":83024,"user":{"displayName":"如子","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3ItGjzEGzUOlXTUHjOgeuVA5TICdNcY-Q1TGicA=s64","userId":"01997730851420384589"}},"outputId":"b683d913-0f00-4ebc-ef36-3f98c867f461"},"source":["chatbot = ChatBot(start_id=None, end_id=tokenizer._token_end_id, maxlen=32)\n","\n","query_li = [\n","  '你好',\n","  '早上好',\n","  '晚上好',\n","  '再见',\n","  '好久不见',\n","  '想死你了',\n","  '谢谢你',\n","  '爱你',\n","  '你叫什么名字',\n","  '你几岁了',\n","  '现在几点了',\n","  '今天天气怎么样',\n","  '我们现在在哪里',\n","  '你能给我讲个笑话吗',\n","  '你是男孩还是女孩呀',\n","  '你会几种语言呀',\n","  '你能陪我玩吗',\n","  '说话可以大声一点吗',\n","  '天气真好',\n","  '天气太糟糕了',\n","  '下雨了',\n","  '雨好大',\n","  '我讨厌艳阳天',\n","  '好晒啊',\n","  '今天好冷',\n","  '今天好热',\n","  '风好大',\n","  '雾太大了看不清路',\n","  '打雷了好可怕',\n","  '下雪了诶',\n","  '好烦啊',\n","  '好开心',\n","  '太激动了',\n","  '我好难过',\n","  '我想哭',\n","  '太好笑了',\n","  '我好伤心',\n","  '心好痛',\n","  '好累啊',\n","  '我好疲惫',\n","  '我爱你',\n","  '我讨厌你',\n","  '你真是太棒啦',\n","  '你好厉害啊',\n","  '吓死我了',\n","  '我想回家',\n","  '我想爸妈了',\n","  '不知道小孩在家有没有听话',\n","  '想回家撸猫',\n","]\n","for q in query_li:\n","  print('Q:', q)\n","  print('A:', chatbot.response([q]))\n","  print()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Q: 你好\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","A: 您好\n","\n","Q: 早上好\n","A: 早啊早啊\n","\n","Q: 晚上好\n","A: 晚上好！\n","\n","Q: 再见\n","A: 我要走了\n","\n","Q: 好久不见\n","A: 是啊，最近怎么样啊\n","\n","Q: 想死你了\n","A: 哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈\n","\n","Q: 谢谢你\n","A: 不谢不谢，\n","\n","Q: 爱你\n","A: 我也爱你，你最美\n","\n","Q: 你叫什么名字\n","A: 你是不是想说我的名字太俗了\n","\n","Q: 你几岁了\n","A: 我不知道\n","\n","Q: 现在几点了\n","A: 我也不知道啊\n","\n","Q: 今天天气怎么样\n","A: 不错\n","\n","Q: 我们现在在哪里\n","A: 在我们宿舍楼下。。。\n","\n","Q: 你能给我讲个笑话吗\n","A: 不能\n","\n","Q: 你是男孩还是女孩呀\n","A: 我是萌妹纸\n","\n","Q: 你会几种语言呀\n","A: 只会说一句\n","\n","Q: 你能陪我玩吗\n","A: 你猜\n","\n","Q: 说话可以大声一点吗\n","A: 我不\n","\n","Q: 天气真好\n","A: 是啊。\n","\n","Q: 天气太糟糕了\n","A: 是的\n","\n","Q: 下雨了\n","A: 我也是\n","\n","Q: 雨好大\n","A: 对呀，我们还穿短袖\n","\n","Q: 我讨厌艳阳天\n","A: 我喜欢\n","\n","Q: 好晒啊\n","A: 是啊，不是很热的\n","\n","Q: 今天好冷\n","A: 是啊。\n","\n","Q: 今天好热\n","A: 对啊，我都热疯\n","\n","Q: 风好大\n","A: 嗯嗯嗯，风好大，冷\n","\n","Q: 雾太大了看不清路\n","A: 你是不是傻啊\n","\n","Q: 打雷了好可怕\n","A: 我们这边下雨了\n","\n","Q: 下雪了诶\n","A: 下了一天了\n","\n","Q: 好烦啊\n","A: 我也是\n","\n","Q: 好开心\n","A: 哈哈哈，我也是！\n","\n","Q: 太激动了\n","A: 哈哈\n","\n","Q: 我好难过\n","A: 你怎么难过\n","\n","Q: 我想哭\n","A: 哭吧哭吧，我陪你哭\n","\n","Q: 太好笑了\n","A: 哈哈\n","\n","Q: 我好伤心\n","A: 你是不是想笑死我！！下次再给你拍\n","\n","Q: 心好痛\n","A: 怎么了\n","\n","Q: 好累啊\n","A: 累了就睡觉\n","\n","Q: 我好疲惫\n","A: 你不是一直都很疲惫么\n","\n","Q: 我爱你\n","A: 爱我就来见面\n","\n","Q: 我讨厌你\n","A: 我也讨厌你\n","\n","Q: 你真是太棒啦\n","A: 谢谢！\n","\n","Q: 你好厉害啊\n","A: 你也可以的\n","\n","Q: 吓死我了\n","A: 哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈哈笑死我了\n","\n","Q: 我想回家\n","A: 回来吧，家真的好啊！\n","\n","Q: 我想爸妈了\n","A: 想我吗\n","\n","Q: 不知道小孩在家有没有听话\n","A: 我也是听不懂啊\n","\n","Q: 想回家撸猫\n","A: 回呀回呀\n","\n"],"name":"stdout"}]}]}